# ğŸš€ ComfyUI-LaoLi-lineup (è€ææ˜¾å­˜æ’é˜Ÿ)

**[ä¸­æ–‡è¯´æ˜](#ä¸­æ–‡è¯´æ˜) | [English](#english)**

---

<a name="ä¸­æ–‡è¯´æ˜"></a>
## ä¸­æ–‡è¯´æ˜

**ComfyUI çš„æ˜¾å­˜äº¤é€šæŒ‡æŒ¥ã€‚ç”¨äºæ˜¾å­˜æœ‰é™æ—¶ä½¿ç”¨å¤§ä½“ç§¯æ¨¡å‹å¡é¡¿/çˆ†æ˜¾å­˜ï¼Œç‰¹åˆ«æ˜¯ Flux/Qwen ç­‰å¤§æ¨¡å‹æŒ‚è½½ ControlNet æ—¶çš„çˆ†æ˜¾å­˜ã€å‡æ­»é—®é¢˜ã€‚**

### ğŸ§ è§£å†³äº†ä»€ä¹ˆç—›ç‚¹ï¼Ÿ
å³ä½¿ä½ æ‹¥æœ‰ 16GB ç”šè‡³ 24GB æ˜¾å­˜çš„æ˜¾å¡ï¼Œåœ¨ä»¥ä¸‹æç«¯åœºæ™¯ä¸­ä¹Ÿç»å¸¸ä¼šé‡åˆ° `CUDA out of memory` æˆ– `invalid argument` æŠ¥é”™ï¼Œç”šè‡³å¯¼è‡´ç”µè„‘å¡æ­»ï¼š
1.  **å¤§æ¨¡å‹ + ControlNetï¼š** æ¯”å¦‚è¿è¡Œ Flux.1 Dev æˆ– QwenImage æ—¶ï¼Œä¸€å¼€ ControlNet å°±é•¿æ—¶é—´å¡é¡¿/ç‚¸æ˜¾å­˜ã€‚
2.  **å¤šé‡å åŠ ï¼š** åŒæ—¶åŠ è½½å¤šä¸ª ControlNetã€IPAdapter æˆ–å¤§é‡ LoRAï¼Œå¯¼è‡´æ˜¾å­˜ç¢ç‰‡åŒ–ä¸¥é‡ã€‚
3.  **è¶…é«˜æ¸…ç”Ÿå›¾ï¼š** è¿›è¡Œé«˜åˆ†è¾¨ç‡æ”¾å¤§æˆ–å¤§ Batch Size ç”Ÿæˆæ—¶ï¼Œæ˜¾å­˜æ— æ³•åŠæ—¶é‡Šæ”¾ã€‚
4.  **æ˜¾å­˜ä¸è¶³ (8G/12G)ï¼š** å°æ˜¾å­˜æ˜¾å¡å¼ºè¡Œè¿è¡Œ SDXL/Flux é‡åŒ–æ¨¡å‹æ—¶ä¸ç¨³å®šã€‚

ComfyUI è‡ªå¸¦çš„ `--lowvram` å‚æ•°æœ‰æ—¶ä¼šå¤±æ•ˆæˆ–å¯¼è‡´å…¶ä»–èŠ‚ç‚¹æŠ¥é”™ï¼Œæœ¬æ’ä»¶æä¾›äº†æ›´å¼ºåŠ›çš„è§£å†³æ–¹æ¡ˆã€‚

### ğŸ’¡ æ ¸å¿ƒåŸç†ï¼šè€ææ’é˜Ÿç­–ç•¥ (Lineup)
æœ¬æ’ä»¶å®æ–½äº†**â€œä¸€æ­¥ä¸€æ¸…â€**çš„ä¸¥æ ¼ç­–ç•¥ã€‚å®ƒä¼šè‡ªåŠ¨è¯†åˆ«æ¨¡å‹ä¸­çš„æ¯ä¸€ä¸ªè®¡ç®—å±‚ï¼ˆBlockï¼‰ï¼Œå¹¶åœ¨æ¯ä¸€å±‚è®¡ç®—å¼€å§‹å‰ï¼Œå¼ºåˆ¶æ‰§è¡Œ **CUDA æµåŒæ­¥** å’Œ **æ˜¾å­˜è½¯æ¸…ç†**ã€‚

*   **ğŸ›¡ï¸ æè‡´é˜²å´©ï¼š** å°±åƒä¸€ä¸ªæœ‰æ´ç™–çš„ç®¡ç†å‘˜ï¼Œæ¯ç®—ä¸€å±‚å°±æ‰“æ‰«ä¸€æ¬¡æ˜¾å­˜ï¼Œç¡®ä¿ ControlNet ç­‰â€œå¤§å—å¤´â€éšæ—¶æœ‰è¿ç»­çš„æ˜¾å­˜ç©ºé—´å¯ç”¨ã€‚
*   **ğŸ§  é›¶é…ç½®å…¨è‡ªåŠ¨ï¼š** ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®å±‚æ•°ï¼Œä»£ç è‡ªåŠ¨é€‚é… Flux1/2, SDXL, Qwen, Wan2.2, SD1.5 ç­‰å„ç§æ¶æ„ã€‚
*   **ğŸ¤ åŸç”Ÿå…¼å®¹ï¼š** ä¸æš´åŠ›æ¬è¿å†…å­˜ï¼ˆè¿™å®¹æ˜“å¯¼è‡´æŠ¥é”™ï¼‰ï¼Œè€Œæ˜¯åˆ©ç”¨ ComfyUI åŸç”Ÿæœºåˆ¶è¿›è¡Œå¼ºåˆ¶ç®¡ç†ï¼Œç¨³å®šç¬¬ä¸€ã€‚

### âš ï¸ å…¼å®¹æ€§é‡è¦æç¤º (å¿…è¯»)
æœ¬æ’ä»¶ä»…æ”¯æŒ **ComfyUI æ ‡å‡†æ¨¡å‹ç±»å‹ (`MODEL`)**ã€‚
*   **âœ… æ”¯æŒï¼š** `Load Checkpoint`, `UNET Loader`, `Load Diffusion Model` ç­‰åŸç”ŸèŠ‚ç‚¹åŠ è½½çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ Flux, SDXL, Pony, QwenImage ç­‰ï¼‰ã€‚
*   **âŒ ä¸æ”¯æŒï¼š** ä½¿ç”¨éæ ‡å‡†å°è£…ç±»å‹çš„æ’ä»¶ï¼Œä¾‹å¦‚ **`ComfyUI-WanVideoWrapper`** (å…¶ä½¿ç”¨çš„æ˜¯ `WANVIDEOMODEL` ç±»å‹)ã€‚è¿™äº›æ’ä»¶é€šå¸¸è‡ªå¸¦äº†æ˜¾å­˜ç®¡ç†æœºåˆ¶ï¼Œæ— æ³•ä¸æœ¬æ’ä»¶ä¸²è”ã€‚

### ğŸ’» ç¡¬ä»¶è¦æ±‚
ç”±äºæœ¬æ’ä»¶ä¼šå°†å¤§é‡æ˜¾å­˜æ•°æ®ä¸´æ—¶æš‚å­˜åˆ°ç³»ç»Ÿå†…å­˜ï¼ˆRAMï¼‰ä¸­ï¼Œå› æ­¤å¯¹**å†…å­˜å®¹é‡**æœ‰ä¸€å®šè¦æ±‚ï¼š
*   **âœ… æ¨èï¼š64GB æˆ–ä»¥ä¸Š** ç³»ç»Ÿå†…å­˜ï¼ˆæœ€ä½³ç¨³å®šæ€§ï¼Œä»å®¹åº”å¯¹æ•°æ®äº¤æ¢ï¼‰ã€‚
*   **âš ï¸ æœ€ä½ï¼š32GB** ç³»ç»Ÿå†…å­˜ï¼ˆå¯ä»¥å°è¯•ï¼Œä½†åœ¨å¤„ç†æå¤æ‚å·¥ä½œæµæ—¶å¯èƒ½ä¼šå‡ºç°å†…å­˜ä¸è¶³ï¼‰ã€‚

### ğŸ“¦ å®‰è£…æ–¹æ³•

1.  è¿›å…¥ä½ çš„ ComfyUI æ’ä»¶ç›®å½•ï¼š
    ```bash
    cd ComfyUI/custom_nodes/
    ```
2.  å…‹éš†æœ¬é¡¹ç›®ï¼š
    ```bash
    git clone https://github.com/Laolilzp/ComfyUI-LaoLi-lineup.git
    ```
3.  é‡å¯ ComfyUIã€‚
<img width="785" height="274" alt="image" src="https://github.com/user-attachments/assets/eaeed326-e390-4a2c-b743-bb7f590e2abc" />

### ğŸ”§ ä½¿ç”¨è¯´æ˜

1.  **æ·»åŠ èŠ‚ç‚¹ï¼š** åœ¨èœå•ä¸­æ‰¾åˆ° `LaoLi Nodes` -> `Optimization` -> `è€æ_LaoLiğŸš€ Lineup (æ˜¾å­˜æ’é˜Ÿ)`ã€‚
2.  **è¿æ¥èŠ‚ç‚¹ï¼š** å¿…é¡»ä¸²è”åœ¨ **å¤§æ¨¡å‹åŠ è½½** ä¹‹åï¼Œ**ä»»ä½•ä½¿ç”¨æ¨¡å‹çš„æ“ä½œ** ä¹‹å‰ã€‚
    *   `model` è¾“å…¥ï¼šè¿å¤§æ¨¡å‹ (Load Checkpoint / UNET Loader)ã€‚
    *   `model` è¾“å‡ºï¼šè¿åˆ° KSamplerã€ControlNetã€LoRA æˆ– IPAdapterã€‚
3.  **å®Œæˆï¼** è¿ä¸Šå³ç”Ÿæ•ˆï¼Œæ— éœ€ä»»ä½•å‚æ•°é…ç½®ã€‚

### âš ï¸ æ€§èƒ½æç¤º
**ç¨³å®šå‹å€’ä¸€åˆ‡ã€‚**
ç”±äºæ’ä»¶å¼ºåˆ¶ GPU åœ¨æ¯ä¸€æ­¥è®¡ç®—å‰è¿›è¡ŒåŒæ­¥å’Œæ¸…ç†ï¼Œé˜»æ–­äº†éƒ¨åˆ†å¹¶è¡ŒåŠ é€Ÿï¼Œç”Ÿæˆé€Ÿåº¦å¯èƒ½ä¼šä¸‹é™ **5% - 15%**ã€‚
*   **æ¨èåœºæ™¯ï¼š** å½“ä½ çš„å·¥ä½œæµå› ä¸ºçˆ†æ˜¾å­˜è€Œ**å®Œå…¨è·‘ä¸é€š**ï¼Œæˆ–è€…é¢‘ç¹æŠ¥é”™æ—¶ï¼Œè¯·åŠ¡å¿…è¯•ç”¨æœ¬æ’ä»¶ã€‚
*   **ä¸æ¨èåœºæ™¯ï¼š** å¦‚æœä½ çš„æ˜¾å­˜éå¸¸å……è¶³ï¼Œä¸”è¿è¡Œéå¸¸ç¨³å®šï¼Œåˆ™ä¸éœ€è¦ä½¿ç”¨æœ¬æ’ä»¶ã€‚ä¸å»ºè®®GGUFç±»å‹çš„æ¨¡å‹ä½¿ç”¨è¯¥èŠ‚ç‚¹ã€‚
   
---

<a name="english"></a>
## English

**The "VRAM Traffic Controller" for ComfyUI. Solves OOM crashes and system freezes when running massive models (Flux/Qwen/Wan2.2) with ControlNet on limited VRAM.**

### ğŸ§ The Problem
Even with a high-end GPU (e.g., 16GB or 24GB VRAM), you might encounter **OOM (Out of Memory)** errors, `CUDA error: invalid argument`, or severe system lag in the following scenarios:
1.  **Large Model + ControlNet:** The base model (e.g., Flux.1 Dev, QwenImage) fits, but enabling ControlNet causes immediate stuttering or crashes.
2.  **Multiple Stack:** Using multiple ControlNets, IPAdapters, or heavy LoRAs simultaneously, causing severe memory fragmentation.
3.  **High Resolution:** High-res upscaling or large batch sizes where VRAM isn't released fast enough.
4.  **Low VRAM (8G/12G):** Trying to run quantized SDXL/Flux models on cards with limited memory.

The native `--lowvram` flag can sometimes fail or conflict with other nodes. This plugin provides a more robust solution.

### ğŸ’¡ The Solution: LaoLi Lineup Strategy
This node implements a strict **"Step-by-Step Cleaning"** strategy. It automatically detects every computation block in your model and forces a **Stream Synchronization + Soft Cache Cleanup** *before* every single calculation step.

*   **ğŸ›¡ï¸ Ultimate Crash Protection:** Acts like a strict memory janitor. It ensures the GPU is clean before the next layer loads, ensuring large models like ControlNet always have continuous space available.
*   **ğŸ§  Zero Config:** Automatically detects model architectures, including **Flux1/2, SDXL, Qwen, Wan2.2, SD1.5**, etc. No manual setup required.
*   **ğŸ¤ Native Compatibility:** Does not move memory tensors manually (which causes bugs). Instead, it leverages ComfyUI's native memory manager to enforce cleanliness.

### âš ï¸ Compatibility Note (Important)
This node only supports the **Standard ComfyUI Model Type (`MODEL`)**.
*   **âœ… Supported:** Models loaded via `Load Checkpoint`, `UNET Loader`, etc. (Flux, SDXL, Pony, QwenImage).
*   **âŒ Not Supported:** Custom wrappers like **`ComfyUI-WanVideoWrapper`** (which uses the `WANVIDEOMODEL` type). These suites typically have their own memory management and cannot be connected to this node.

### ğŸ’» Hardware Requirements
Since this strategy offloads VRAM data to your System RAM during processing, adequate memory is crucial:
*   **âœ… Recommended: 64GB+** System RAM (Best performance and stability).
*   **âš ï¸ Minimum: 32GB** System RAM (You can try, but it might struggle with extremely large/complex workflows).

### ğŸ“¦ Installation

1.  Navigate to your ComfyUI custom nodes directory:
    ```bash
    cd ComfyUI/custom_nodes/
    ```
2.  Clone this repository:
    ```bash
    git clone https://github.com/Laolilzp/ComfyUI-LaoLi-lineup.git
    ```
3.  Restart ComfyUI.
<img width="785" height="274" alt="image" src="https://github.com/user-attachments/assets/64274757-95e4-4b32-a946-838fef99dbcf" />

### ğŸ”§ Usage

1.  **Add Node:** Right-click -> `LaoLi Nodes` -> `Optimization` -> `è€æ_LaoLiğŸš€ Lineup (æ˜¾å­˜æ’é˜Ÿ)`.
2.  **Connect:** Place it strictly **after** loading the model and **before** any sampling/lora/controlnet operations.
    *   `Model Input` -> Connect to `Load Checkpoint` / `UNET Loader`.
    *   `Model Output` -> Connect to `KSampler`, `Load LoRA`, `IPAdapter` or `Apply ControlNet`.
3.  **Done!** It runs automatically without any parameters.

### âš ï¸ Performance Note
**Stability > Speed.**
Since this node forces the GPU to synchronize and clean memory at every single step, preventing some parallel acceleration, generation speed may decrease by **5% - 15%**.
*   **Recommended:** Try to use this when your workflow **cannot run** due to OOM or crashes.
*   **Not Recommended:** If your VRAM is sufficient and workflows run stably, you do not need this node.

---

### ğŸ“„ License

MIT License



